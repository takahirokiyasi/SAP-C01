# EMR（Elastic MapReduce）
データレイクに溜められたデータを分散処理によって（Hadoop Spark）を使って分析・処理を行うサービス
YARN、HDFS、Apache Spark、Apache HBase、Apache Hive など多彩なアプリケーション用マルチマスターを 1 つのチェックボックスで構成できる。

Amazon EMR の中心的なコンポーネントはクラスターです。クラスターとは、Amazon Elastic Compute Cloud (Amazon EC2) インスタンスのコレクションのことです。クラスター内の各インスタンスは、ノードと呼ばれます。各ノードには、クラスター内での役割があり、ノードタイプと呼ばれます。Amazon EMR は、各ノードタイプにさまざまなソフトウェアコンポーネントもインストールし、Apache Hadoop などの分散型アプリケーションでの役割を各ノードに付与します。

EMRでSQLクエリを使用した分析は実施できない
現在Redhatサーバーで実行されているプロセスを再現することはできないため、ECインスタンスにRedhatサーバーをインストールして解析ソフトウェア自体を移行する方が適切
コンピューティング（EMR）とストレージ（S3）を個別にスケーリング
ストレージはS3を基本的に使用する
ストレージとコンピューティングを分離することで１つのストレージに対して複数のクラスターから処理を行うことができる

spark streamingとか言ってkinesisから直接データをストリーミングもできるし
DynamoDBに相互にデータ送りあったりもできる。

任意のサブネットに配置できる。

## ノードタイプ
### マスターノード
処理を行うために他のノード間でのデータおよびタスクの分散を調整するソフトウェアコンポーネントを実行することで、クラスターを管理するノードです。マスターノードは、タスクのステータスを追跡し、クラスターの状態を監視します。すべてのクラスターにはマスターノードがあり、マスターノードのみで1つのノードクラスターを作成することが可能
マスターノードは稼働し続けないといけない

マルチマスターのオブションを有効化すると3つのマスターノードを持つクラスターが作成される。

### コアノード 
タスクを実行し、クラスター上の Hadoop Distributed File System (HDFS) に`データを保存`するソフトウェアコンポーネントを持つノードです。マルチノードクラスターには、少なくとも 1 つのコアノードがあります。

### タスクノード
タスクを実行するのみで、HDFS にデータを保存しないソフトウェアコンポーネントを持つノードです。タスクノードはオプションです。

### インスタンスの割り当て
`中長期的に使用する場合`は`マスターノードやコアノードにはリザーブドインスタンス`を利用して、ジョブに割り当てられる`タスクノードにはスポットインスタンス`を使用することが望ましい
短期的ならば全部スポットインスタンスでも問題ないっぽい

コアとタスクにはAuto Scaling設定可能

## Hadoopの基礎知識
### HDFS（Hadoop Distributed File System）
分散処理システムのHadoopが利用している分散ファイルシステムです。HDFSは管理するファイルの読み書きを高速化するため、大きなファイルを一定の大きさのブロックに分割し、複数の記憶装置に分散して保存、読み込みや書き込みを記憶装置の台数だけ並列に実行できるようにします。その際、同じブロックを複数の装置に同時に記録し、耐障害性を高めており、保存するデータの3倍の記憶領域が消費されます。

### Apatch  Spark
Sparkのインタフェースを使うと、暗黙のデータ並列性と耐故障性を備えたクラスタ全体をプログラミングでき、ストリームデータの高速並列処理が可能

### Apache Hive
Hadoopの上に構築されたデータウェアハウス構築環境であり、データの集約・問い合わせ・分析を行うことができる

## 他のサービスとの比較
### Athena
AthenaはS3しかデータソースにできないのでそれ以外もデータソースにしたいならEMR
またAthenaは同時実行クエリ数の制限があるのでそれを回避したいならEMR（Presto on Amazon EMR）
### Glue
ELT処理にSpark以外を使いたい。Spotインスタンスを使いたい場合はEMR

# Athena
`サーバーレス`なクエリサービスで、S3内のデータを標準SQLを使って分析できる
Glueデータカタログと統合されていて、メタデータの統合リポジトリを作成できる

# Glue
データソースからのデータの抽出
データの取り込みや分析をしやすいデータ形式への変換
データ分析基盤に対するデータの取り込み
と言うETLタスク(バッチ処理)をマネージドで提供する`サーバーレス`なサービス

各種AWSサービスの間を繋ぐ「糊(Glue)」(オンプレもいけるけど)

## リソース接続について
`デフォルトでは、AWS GlueからVPC内のリソースにアクセスすることはできない`
ジョブを VPC サブネットで実行する必要がある場合、VPC 内の他のリソースに安全に接続できるようにするENI(Elastic Network Interfaces) を設定する。
ENIにはサブネット内の IP アドレス範囲からプライベートIPアドレスが割り振られる。
ちなみにVPC 内から Amazon S3 にアクセスするには VPC エンドポイントが必須

## クローラー
データソースのメタデータ（スキーマ定義やデータ構造）をクロールする。
DynamoDB　S3　Redshift RDS EC2上のRDB　各種オンプレミスのJDBCデータストアにも接続に対応（S3もしくはJDBC接続できるやつは全部いける認識でOK）
自動でパーティションを判定してくれたりする。
データカタログにメタデータを保存する

S3・DynamoDBにはIAMロールでアクセス
Redshift・RDS・オンプレミスDB・RDBonEC2はJDBCでアクセス

## データカタログ
Apache Hiveメタストア（テーブル定義だけを格納する機能）互換のメタデータレポジトリ
データカタログにはメタデータに関するテーブルが作成される（csvがデータ元だとそれぞれのカラムの名前や型、URLなどデータそのものの場所のとか）
保存したスキーマをバージョン管理・変更することが可能

## Amazon S3 データレイクに対するクエリ
Redshift EMR Athanaを使用してS3上のデータに対して処理をする場合。
クローラーによるデータ検索が行い、テーブル定義やスキーマなどの関連するメタデータをAWS Glue データカタログに保存する。Data Catalog 内のメタデータを使用して、S3内の実データに対してRedshiftのクエリ、EMRのジョブを実行することができる。

## ジョブ
ETLの処理単位をジョブといい、ジョブの種類にはApacheSpark（並列分散処理ができるので大規模処理はこれ）とPython Shell（中規模処理はこれ　メモリがLabmdaより多いしPythonライブラリが使えて便利）がある。
ETLジョブはデータカタログのスキーマ情報を使用できる
ジョブの状態をブックマーク機能で保持可能（処理済みデータを再度処理しないように回避できたりする）
SparkSQLを用いて、DataFrameを操作する（事前にテーブル定義が必要）

### DPU
ジョブの処理能力をDPU（Data Processing Unit）という
1DPU = 4vCP, 16GBメモリ

### DynamicFrame
SparkSQLのDataFrameと違いETLに特化している。
１カラムに複数の型の可能性を残すことができるChoice型なるものがある（数値型が途中でデータが変わり文字列になったり）

## トリガー
ジョブを定期実行するための定義を設定できる機能

## ワークフロー機能
DAG（有向非巡回グラフ）のワークフローを作成できる
クローラー、トリガー、ジョブでワークフローを構成

## VPCへのアクセス
プライベートサブネットにプライベートIPが付与されたENIが作成される
S3と接続する場合はVPCエンドポイント
ネットと通信する場合はNAT gateway

### セキュリティグループの設定
RDS・Redshiftなどインスタンス単位でアクセス制御を行う場合、Glueからアクセスできるように自己参照型のセキュリティグループ（RDS自身のセキュリティグループからの接続を許可する設定　ポートはALL）を設定する。

## モニタリング
Cloud Watch Eventsをクローラー、ジョブのステータスをトリガーに実行可能
ジョブの実行状況はCloudWatch　Logsで確認可能
Job Metricsオプションを有効にすることでジョブ監視とデバッグが可能（メモリ使用率・DPU・複数ジョブの実行状況等）
### Continuous Logging
Spark　ETLジョブの進捗状況をリアルタイムに追跡できる機能

# Kinesis
## Kinesis Data Streams
レコードの順序付け、および複数のAmazon Kinesisアプリケーションに対して同じ順序でレコードを読み取ったり再生したりする機能を提供
複数のアプリケーションで同じデータを参照したり時間がたってから再度同じデータを参照するということが可能
- デフォルトで２４時間レコードを保持する(データを蓄積する要件には向かない)
- SQSとAmazon Kinesis Data Streamsを一緒に利用する必要はない
- データの種類や用途に応じてストリームを作成する。ストリームは１つ以上のシャードによって構成される。
- データは「データレコード」と呼ばれる
- データレコードにはシーケンス番号がふられ、順番が保証される
- タスクの実行にはLambdaなどが必要
- シャードの数は一度に2倍までしか無理

### Kinesis エージェント
データ送信側(プロデューサー)
スタンドアロンの Java ソフトウェアアプリケーションで、データを収集して Kinesis Data Streams に送信する簡単な方法を提供する。

### Kinesis Producer Library(KPL)
データ送信側(プロデューサー)
Kinesis Data Streamsにデータを送信するOSSのライブラリ

Aggregation：複数件のデータを 1 データレコードに集約して送信可能
Collection：複数のレコードをバッファリングして送信

### Fluent plugin for Amazon Kinesis
データ送信側(プロデューサー)
Fluentd をログ収集に使っているなら、このプラグインを追加するだけで AmazonKinesis へのデータ投入がすぐにできる

### Amazon Kinesis Data Generator (KDG)
データ送信側(プロデューサー)
Amazon Kinesis Streams または Amazon Kinesis Firehose に`テストデータ`を簡単に送信できる

### Amazon Kinesis Client Library(KCL)
コンシューマー (データ処理側)
Java、Ruby、Python、Node.js の開発に利用できる OSSのクライアントライブラリ
Kinesisアプリケーションを構築し、ストリーミングデータを使用してリアルタイムダッシュボードの強化、アラートの生成、動的な価格設定と広告の実装などを行うことができます。 Kinesis Data StreamsからAmazon Simple Storage Service（Amazon S3）、Amazon Redshift、Amazon EMR、AWS Lambdaなどの他のAWSサービスにデータを送信することが可能です。今回は目的であれば、大量のストリームデータをS3に蓄積して、 Redshiftによる解析を実施することができます

1. Record Processor Factory 
  レコードプロセッサーを作る
2. Record Processor
Amazon Kinesis Streamsのシャードから取り出したデータを処理するプロセッサーの単位
3. Worker
個々のアプリケーションインスタンスとマッピングする処理単位
KCL WorkerはStreamと対応してログを受け取るプログラムのこと

### シャードが不十分な場合の対処法
#### リシャーディング
シャードの分割を行いデータ容量を増やす
シャードの分割では１ つのシャードを 2 つシャードに分けます。シャードの結合では、2 つシャードを 1 つのシャードに組み合わせます。リシャーディングは、1 回のオペレーションでシャードに分割できる数と 1 回のオペレーションで結合できるシャードの数が 2 個以下に限られるという意味で、常にペアワイズです。リシャーディングオペレーションの対象となるシャードまたはシャードペアは、親シャードと呼ばれます。リシャーディングオペレーションを実行した結果のシャードまたはシャードペアは、子シャードと呼ばれます。 分割によりストリーム内のシャードの数が増え、したがってストリームのデータ容量は増えます。シャード単位で請求されるため、分割によりストリームのコストが増えます。

#### シャードに合わせたインスタンスサイズの増強
Kinesisストリーム内のインスタンスのサイズとシャードの数を増やすことで、インスタンスがインスタンス内で並行して実行されるより多くのレコードプロセッサを処理できるようにします。 また、ストリームが送信されるデータのレートに適切に対応できるようにします。ストリームのデータ容量は、ストリームに指定するシャードの数の関数です。

## Amazon Kinesis Video Streams
動画はこちらを使う

### HTTP Live Streaming (HLS)機能
HTTP Live Streaming (HLS) は、業界標準の HTTP ベースのメディアストリーミング通信プロトコルです。HLS を使用して、ライブ再生またはアーカイブ済み動画の再生用に Amazon Kinesis ビデオストリーム を表示できます。

Kinesis Video Streams の HTTP Live Streaming (HLS) 機能を使用して、ライブ動画や録画したメディアを Kinesis Video Streams からお使いのブラウザまたはモバイルアプリケーションに簡単にストリーミングできます。
HLSをサポートするサードパーティプレーヤーを使用してKinesis Video Streamsと統合できる

#### GetHLSStreamingSessionURL API
GetHLSStreamingSessionURL APIによりHLSストリーミングセッションURLを取得することができます。
HLSストリーミングセッションURLを取得したら、ビデオを再生できるビデオプレーヤーに提供します。 

### GetMedia API
GetMedia API を使用して、Kinesis ビデオ ストリームを処理する独自のアプリケーションを構築します。GetMedia は低レイテンシーのリアルタイム API です。GetMedia を使用するプレーヤーを作成する場合は、自分で構築してビルドする必要があるため、めんどくさいから基本的に`GetHLSStreamingSessionURL API`を使用する方が良い。

### MPEG-DASH
Dynamic Adaptive Streaming over HTTP (DASH) (MPEG-DASH とも呼ばれる) は、従来の HTTP ウェブサーバーから配信されたインターネット経由で高品質のストリーミングを可能にする適応ビットレートストリーミングプロトコルです。 

## Kinesis Data Firehose
ストリーミングデータをデータレイクやデータストア、分析ツールに確実にロードする
ストリーミングデータ(IoT機器のデータやCloudWatchLogsのログなど)をキャプチャして変換し、Amazon S3、Amazon Redshift、Amazon Elasticsearch Service、Splunk にロードする
配信ストリームを作成してデータを配信
Lambdaを利用したデータの変形が可能

### Data FirehoseとData Streamsの違い
Kinesis Streamsの最大の特徴はレイテンシの速さ、次々に上がってくるデータの内容をリアルタイムに加工、表示させたいと言うニーズに対応（Streamsは1秒以下で処理、Firehoseは60秒ほど）
Kinesis Firehoseの特徴はゼロ管理でコードを書く必要がほぼない。分析目的でS3とかに貯める目的なのでそこまでリアルタイム性いらない

[Data FirehoseとData Streamsの違い](https://dev.classmethod.jp/articles/difference-between-kinesis-streams-and-kinesis-firehose/)

## Amazon Kinesis S3コネクター
Amazon Kinesis から Amazon S3 にデータをアーカイブすることができます。Amazon Kinesis コネクタライブラリを使用すると Amazon Kinesis を他の AWS サービスやサードパーティー製ツールと簡単に統合できるようになります。
Amazon Kinesis コネクタライブラリを使用するには、Amazon Kinesis クライアントライブラリ (KCL) が必要です。このライブラリの現在のバージョンでは、Amazon DynamoDB、Amazon Redshift、Amazon S3、Amazon Elasticsearch Service に対するコネクタが提供されています。

## Kinesis Analytics
datastreamやfirehoseからデータを受け取る
ストリームデータを標準的なSQLクエリでリアルタイムに分析　分析結果を再度DataStreamsやFirehoseに流すこと可能
SQLクエリ実行前に、Lambdaによる前処理可能

# Amazon　Elasticsearch Service（ES）
ElasticsearchとKibanaを簡単にデプロイ・管理しスケールさせることが可能なサービス

## 二種類のAPI
### 設定API
Amazon ESサービスのAPIでAmazon ESドメイン（Elasticsearch クラスターのこと）やタグ、サービスロール等の操作を行うためのもの
### Elasticsearch API
Amazon ES上で動くElasticsearchクラスタのAPI、インデックスの作成や削除、ドキュメントの追加、検索クエリの実行等の操作を行うためのもの

使用できるインスタンスタイプは制限がある
C4 C5 I2 I3 など

## 構成
Elasticsearchはクラスターにマスターノード・データノードをもつ
### クラスター（ドメイン）
クラスター（ドメイン）はパブリックIPを持ちインターネットからアクセス可能な`パブリックドメイン`とVPC経由でのみアクセス可能な`VPCドメイン`の二種類がある
## マスター
データノードの管理をマスターノードがしている（マスターノードの障害時、クラスターのオベレーションができなくなってしまう）
マスターノードには専用マスターとマスター候補がいる。
マスターノードに障害が起こった場合に次のマスターを選出するには最低三台必要（AWSではなくElasticsearch側の仕様）
AZは分散させる
### 専用マスターノード
インスタンスにおいてマスターノードとデータノードは同居可能だが、頻繁なデータ挿入や検索によりデータノードの負荷が高まった時、マスターノードの挙動が不安定になるため、専用のマスターノードを利用するのが推奨

## ESを使ったログ分析
Kinesis Data Streams（Lambda経由）・Kinesis Data Firehose・AWS IoT・S３（Lambda経由）・CloudWatch　Logs(Lambda経由でAPIを叩く)からESにデータを挿入できる

Elasticsearch検索APIでも検索できるが、SQLインターフェイスがサポートしていて、SQLを使ったデータ分析が可能

クラスターを横断したクエリ実行が可能になった（Amazon ESの独自機能）

### Ultrawarmノード
`大規模ログ分析を低コスト`で実現するためのAmazon ESオリジナルのノードタイプ
S3に保持したデータに対してクエリを実行
Ultrawarmノードに移動されたインデックスは読み取り専用になる
APIを読んでデータノードに移動させたりUltrawarmノードに移動させたりできる _hotでデータノードに　_warmでUltrawarmノードに

## ESによる全文検索
日本語ではKuromojiプラグインで形態素解析できたりする
カスタム辞書をインデックス作成時に登録できる
KNN使ってみたりもできる

## ESの管理
### Index State Management(ISM)でインデックスの自動管理
３０日たったらそのインデックスはあまり使わないとか、７日経ったらインデックス削除したいとかのニーズに対応できる
Kibana上でインデックス管理ポリシーを作成・管理してそれを反映させる

### ロギング
#### Elasticsearch APIのログ
デフォルト無効
インデックススローログ・検索スローログ・エラーログをCloudWatchに出力

#### 設定APIのログ
CloudTrailにAPIコールのログを出力される

### メトリクス
CPUUtilization(CPU使用率)
JVMMemoryPressure(Elasticsearchで使われているJVMのメモリの使用率)
などをアラート設定しとけばOK

#### 検索APIベースのアラート
レコード数がいくらになったらとかでアラートすることができる
SNS　Webhookが対応
異常検知のアルゴリズムを使用可能（Ramdam Cut Forest）

### スナップショット
基本的に自動でクラスターのバックアップのスナップショットを取得してくれるが（追加料金なし）
異なるAmazon ESドメインにデータを移行したい場合は手動での取得が必要（S3の利用料金）

### on EC2からの移行
スナップショットのAPIを叩いてS3にスナップショットを保存しESにリストア

## 認証と認可
### IAMベースでのアクセスポリシー
アイデンティティベース（IAMロール・ユーザー）
リソースベース（ESドメインに対して）の２つが設定可能
指定がない場合デフォルトDeny
### Open Distroベースのドメイン内さぶリソースに対する詳細なアクセス権限管理
